input <- read_excel("DataSet_AntimicrobialPeptides_Descriptors.xlsx")
setwd("C:/Users/eliez/OneDrive/Tesis y titulacion/Antimicrobial_Peptides_QSAR_Prediction_Project/Models/Regresion PeptidesVsGramN")
t0 = now()
# Filtro inicio
input_selected <- input %>%
rename(logMIC = "Mesure_(log)") %>%
rename(hoopwoods_1_mean = "hopp-woods_1_mean") %>%
filter(Cuantification_Type == "MIC" &
Target_Type =="Bacteria Gram Negative" &
Unity == "µg/ml"  &
is.na(Notes))
# Delete NA values in logMIC and filter Unity
input_naomit <- input_selected %>%
mutate(logMIC = as.numeric(logMIC)) %>%
drop_na(logMIC)
# Eliminar duplicados
input_naomit_out_dup <- input_naomit %>%
distinct(Sequences,.keep_all = TRUE)
ggpubr::gghistogram(input_naomit_out_dup$logMIC)
# Remove outlier in general
input_naomit_out_dup <-  input_naomit_out_dup %>%
rstatix::identify_outliers(logMIC) %>%
anti_join(input_naomit_out_dup,.)
#print(table(input$Genero))
###############
set.seed(321)
index <- createDataPartition(input_naomit_out_dup$logMIC,
p = .8, list = FALSE)
train_input <- input_naomit_out_dup[ index,]
test_input  <- input_naomit_out_dup[-index,]
# Check distributions
train_input %>% mutate(set = "Train") %>%
rbind(test_input %>% mutate(set = "Test")) %>%
ggplot(aes(logMIC, color = set)) +
geom_density()
# Seleccionar variables de informacion
train_info <- train_input %>%
select(Data_ID:References)
test_info <- test_input %>%
select(Data_ID:References)
# Seleccionar variable respuesta y descriptores
train_set <- train_input %>%
select(logMIC, Y:KGA)
test_set <- test_input %>%
select(logMIC, Y:KGA)
#PREPROCESAMIENTO
rec_train <- recipe(logMIC ~ . , data = train_set) %>%
step_nzv(all_predictors()) %>%
step_corr(all_numeric_predictors(), threshold = 0.85) %>%
#step_normalize(all_numeric_predictors()) %>%
step_scale(all_predictors()) %>%
prep()
train_prep <- juice(rec_train)
test_prep <- bake(rec_train, new_data = test_input)
########         SELECCION DE CARACTERISTICAS
# Cargar librerias
packages_load <- c("caret", "caretEnsemble", "doParallel", "gbm",
"dplyr")
for (i in packages_load) {
library(i, character.only  = TRUE)
}
# Usar varios nucleos
no_cores <- detectCores()
cl <- makePSOCKcluster(no_cores, outfile = "modeling.log")
registerDoParallel(cl)
load("C:/Users/eliez/OneDrive/Tesis y titulacion/Antimicrobial_Peptides_QSAR_Prediction_Project/Models/Regresion PeptidesVsGramN/rf_fs.rda")
t2 = now()
print(t2-t1)
# Plot
plot(rf_fs)
t3 = now()
print(t3-t0)
load("C:/Users/eliez/OneDrive/Tesis y titulacion/Antimicrobial_Peptides_QSAR_Prediction_Project/Models/Regresion PeptidesVsGramN/fs_ga.rda")
#---------------------------------------------------------------------
#ALGORITMO GENETICO
x_rfe <- train_prep %>% select(predictors(rf_fs))
y_rfe <- train_prep$logMIC
# El grafico muestra en el eje x: la generacion y, en el eje y: la meadia del RMSE.
plot(fs_ga)
svglite::svglite(filename = "plt_fs_ga.svg",
width = 8, height = 6)
plot(fs_ga)
dev.off()
#---------------------------------------------------------------------
#MODELOS
#NUEVO ALGORITMO DE PREPROCESAMIENTO CON MENOS VARIABLES (los valores no cambian)
train_set2 <- train_set %>%
select(fs_ga$optVariables) # Seleccionando las mejores variables segun AG
rec_train2 <- recipe( ~ . , data = train_set2) %>%
step_nzv(all_predictors()) %>%
step_corr(all_numeric_predictors(), threshold = 0.85) %>%
#step_normalize(all_numeric_predictors()) %>%
step_scale(all_predictors()) %>%
prep()
train_prep2 <- juice(rec_train2)
save(rec_train2, file = "FinalPreprocessing_algoritm.rda")
# List of models and hyperparameters
mod_tune <- 20
# Methods
models <- list(
lm = caretModelSpec(method = "lm"),
pls = caretModelSpec(method = "pls", tuneLength = 2),
svmLinear = caretModelSpec(method = "svmLinear", tuneLength = 2),
svmRadial = caretModelSpec(method = "svmRadial", tuneLength = 2),
svmPoly = caretModelSpec(method = "svmPoly", tuneLength = 2),
rf = caretModelSpec(method = "rf", tuneLength = 2),
gbm = caretModelSpec(method = "gbm")
)
# Cross validation paramters
outcome <- "logMIC"
y_vector <- train_prep %>% as.data.frame() %>% .[,outcome]
set.seed(123)
fivecv_5_multi <- trainControl(method = "repeatedcv",
number = 2,
repeats = 2,
verboseIter = TRUE,
allowParallel = TRUE,
savePredictions = "final",
index =
createMultiFolds(y_vector, 2, 2))
# Final dataset
Train_fs_logMic <- train_prep %>% select(logMIC,
fs_ga$optVariables) %>% as.data.frame()
# Regression logMIC
models_logMIC <- caretList(logMIC~., data = Train_fs_logMic,
trControl = fivecv_5_multi,
tuneList = models,
continue_on_fail = TRUE)
#_-------------------------------------------
#METRICAS
get_metric <- function(result_models, train_fs, outcome){
models_sel <- result_models %>% names()
tr_metric <- result_models %>%
.[models_sel] %>%
map(predict, train_fs) %>%
map(postResample, train_fs[,outcome]) %>%
bind_rows(.id = "model") %>%
mutate(set = "Train")
ts_metric <- result_models %>%
.[models_sel] %>%
map(predict, test_prep) %>%
map(postResample, test_prep %>% pull(outcome)) %>%
bind_rows(.id = "model") %>%
mutate(set = "Test")
if(outcome == "logMIC") {
cv_metric <- result_models %>%
.[models_sel] %>%
map(pluck, "resample") %>%
map(summarise, RMSE = mean(RMSE),
Rsquared = mean(Rsquared), MAE = mean(MAE)) %>%
bind_rows(., .id = "model") %>% mutate(set = "cv")
}
if(outcome != "logMIC") {
cv_metric <- result_models %>%
.[models_sel] %>%
map(pluck, "resample") %>%
map(summarise, Accuracy = mean(Accuracy),
Kappa = mean(Kappa)) %>%
bind_rows(., .id = "model") %>% mutate(set = "cv")
}
metric_models <- rbind(tr_metric, cv_metric, ts_metric) %>%   arrange(model)
}
metric_logMIC <- get_metric(models_logMIC, Train_fs_logMic, "logMIC")
View(metric_logMIC)
# Final dataset
Train_fs_logMic <- train_prep %>% select(logMIC,
rf_fs$optVariables) %>% as.data.frame()
# Regression logMIC
models_logMIC <- caretList(logMIC~., data = Train_fs_logMic,
trControl = fivecv_5_multi,
tuneList = models,
continue_on_fail = TRUE)
#_-------------------------------------------
#METRICAS
get_metric <- function(result_models, train_fs, outcome){
models_sel <- result_models %>% names()
tr_metric <- result_models %>%
.[models_sel] %>%
map(predict, train_fs) %>%
map(postResample, train_fs[,outcome]) %>%
bind_rows(.id = "model") %>%
mutate(set = "Train")
ts_metric <- result_models %>%
.[models_sel] %>%
map(predict, test_prep) %>%
map(postResample, test_prep %>% pull(outcome)) %>%
bind_rows(.id = "model") %>%
mutate(set = "Test")
if(outcome == "logMIC") {
cv_metric <- result_models %>%
.[models_sel] %>%
map(pluck, "resample") %>%
map(summarise, RMSE = mean(RMSE),
Rsquared = mean(Rsquared), MAE = mean(MAE)) %>%
bind_rows(., .id = "model") %>% mutate(set = "cv")
}
if(outcome != "logMIC") {
cv_metric <- result_models %>%
.[models_sel] %>%
map(pluck, "resample") %>%
map(summarise, Accuracy = mean(Accuracy),
Kappa = mean(Kappa)) %>%
bind_rows(., .id = "model") %>% mutate(set = "cv")
}
metric_models <- rbind(tr_metric, cv_metric, ts_metric) %>%   arrange(model)
}
metric_logMIC <- get_metric(models_logMIC, Train_fs_logMic, "logMIC")
View(metric_logMIC)
#---------------------------------------------------------------------
#MODELOS
#NUEVO ALGORITMO DE PREPROCESAMIENTO CON MENOS VARIABLES (los valores no cambian)
train_set2 <- train_set %>%
select(fs_ga$optVariables) # Seleccionando las mejores variables segun AG
rec_train2 <- recipe( ~ . , data = train_set2) %>%
step_nzv(all_predictors()) %>%
step_corr(all_numeric_predictors(), threshold = 0.85) %>%
#step_normalize(all_numeric_predictors()) %>%
step_scale(all_predictors()) %>%
prep()
train_prep2 <- juice(rec_train2)
save(rec_train2, file = "FinalPreprocessing_algoritm.rda")
# List of models and hyperparameters
mod_tune <- 20
# Methods
models <- list(
lm = caretModelSpec(method = "lm"),
pls = caretModelSpec(method = "pls", tuneLength = 20),
svmLinear = caretModelSpec(method = "svmLinear", tuneLength = 10),
svmRadial = caretModelSpec(method = "svmRadial", tuneLength = 10),
svmPoly = caretModelSpec(method = "svmPoly", tuneLength = 5),
rf = caretModelSpec(method = "rf", tuneLength = 10),
gbm = caretModelSpec(method = "gbm")
)
# Cross validation paramters
outcome <- "logMIC"
y_vector <- train_prep %>% as.data.frame() %>% .[,outcome]
set.seed(123)
fivecv_5_multi <- trainControl(method = "repeatedcv",
number = 5,
repeats = 5,
verboseIter = TRUE,
allowParallel = TRUE,
savePredictions = "final",
index =
createMultiFolds(y_vector, 5, 5))
# Final dataset
Train_fs_logMic <- train_prep %>% select(logMIC,
fs_ga$optVariables) %>% as.data.frame()
# Regression logMIC
models_logMIC <- caretList(logMIC~., data = Train_fs_logMic,
trControl = fivecv_5_multi,
tuneList = models,
continue_on_fail = TRUE)
# List of models and hyperparameters
mod_tune <- 20
# Methods
models <- list(
lm = caretModelSpec(method = "lm"),
pls = caretModelSpec(method = "pls", tuneLength = 20),
svmLinear = caretModelSpec(method = "svmLinear", tuneLength = 10),
svmRadial = caretModelSpec(method = "svmRadial", tuneLength = 10),
svmPoly = caretModelSpec(method = "svmPoly", tuneLength = 3),
rf = caretModelSpec(method = "rf", tuneLength = 10),
gbm = caretModelSpec(method = "gbm")
)
# Cross validation paramters
outcome <- "logMIC"
y_vector <- train_prep %>% as.data.frame() %>% .[,outcome]
set.seed(123)
fivecv_5_multi <- trainControl(method = "repeatedcv",
number = 5,
repeats = 5,
verboseIter = TRUE,
allowParallel = TRUE,
savePredictions = "final",
index =
createMultiFolds(y_vector, 5, 5))
# Final dataset
Train_fs_logMic <- train_prep %>% select(logMIC,
fs_ga$optVariables) %>% as.data.frame()
# Regression logMIC
models_logMIC <- caretList(logMIC~., data = Train_fs_logMic,
trControl = fivecv_5_multi,
tuneList = models,
continue_on_fail = TRUE)
save(models_logMIC, file = "models_logMIC.rda")
#_-------------------------------------------
#METRICAS
get_metric <- function(result_models, train_fs, outcome){
models_sel <- result_models %>% names()
tr_metric <- result_models %>%
.[models_sel] %>%
map(predict, train_fs) %>%
map(postResample, train_fs[,outcome]) %>%
bind_rows(.id = "model") %>%
mutate(set = "Train")
ts_metric <- result_models %>%
.[models_sel] %>%
map(predict, test_prep) %>%
map(postResample, test_prep %>% pull(outcome)) %>%
bind_rows(.id = "model") %>%
mutate(set = "Test")
if(outcome == "logMIC") {
cv_metric <- result_models %>%
.[models_sel] %>%
map(pluck, "resample") %>%
map(summarise, RMSE = mean(RMSE),
Rsquared = mean(Rsquared), MAE = mean(MAE)) %>%
bind_rows(., .id = "model") %>% mutate(set = "cv")
}
if(outcome != "logMIC") {
cv_metric <- result_models %>%
.[models_sel] %>%
map(pluck, "resample") %>%
map(summarise, Accuracy = mean(Accuracy),
Kappa = mean(Kappa)) %>%
bind_rows(., .id = "model") %>% mutate(set = "cv")
}
metric_models <- rbind(tr_metric, cv_metric, ts_metric) %>%   arrange(model)
}
metric_logMIC <- get_metric(models_logMIC, Train_fs_logMic, "logMIC")
xlsx::write.xlsx(metric_logMIC,file='metricslogMIC.xlsx')
View(metric_logMIC)
#_-------------------------------------------
#METRICAS
get_metric <- function(result_models, train_fs, outcome){
models_sel <- result_models %>% names()
tr_metric <- result_models %>%
.[models_sel] %>%
map(predict, train_fs) %>%
map(postResample, train_fs[,outcome]) %>%
bind_rows(.id = "model") %>%
mutate(set = "Train")
ts_metric <- result_models %>%
.[models_sel] %>%
map(predict, test_prep) %>%
map(postResample, test_prep %>% pull(outcome)) %>%
bind_rows(.id = "model") %>%
mutate(set = "Test")
if(outcome == "logMIC") {
cv_metric <- result_models %>%
.[models_sel] %>%
map(pluck, "resample") %>%
map(summarise, RMSE = mean(RMSE),
Rsquared = mean(Rsquared), MAE = mean(MAE)) %>%
bind_rows(., .id = "model") %>% mutate(set = "cv")
}
if(outcome != "logMIC") {
cv_metric <- result_models %>%
.[models_sel] %>%
map(pluck, "resample") %>%
map(summarise, Accuracy = mean(Accuracy),
Kappa = mean(Kappa)) %>%
bind_rows(., .id = "model") %>% mutate(set = "cv")
}
metric_models <- rbind(tr_metric, cv_metric, ts_metric) %>%   arrange(model)
}
metric_logMIC <- get_metric(models_logMIC, Train_fs_logMic, "logMIC")
metric_logMIC
setwd("C:/Users/eliez/OneDrive/Tesis y titulacion/Antimicrobial_Peptides_QSAR_Prediction_Project/Models/Regresion PeptidesVsGramN")
View(models_logMIC)
#---------------------------------------------------------------------
#MODELOS
#NUEVO ALGORITMO DE PREPROCESAMIENTO CON MENOS VARIABLES (los valores no cambian)
train_set2 <- train_set %>%
select(fs_ga$optVariables) # Seleccionando las mejores variables segun AG
rec_train2 <- recipe( ~ . , data = train_set2) %>%
step_nzv(all_predictors()) %>%
step_corr(all_numeric_predictors(), threshold = 0.85) %>%
#step_normalize(all_numeric_predictors()) %>%
step_scale(all_predictors()) %>%
prep()
train_prep2 <- juice(rec_train2)
save(rec_train2, file = "FinalPreprocessing_algoritm.rda")
# List of models and hyperparameters
mod_tune <- 20
# Methods
models <- list(
lm = caretModelSpec(method = "lm"),
pls = caretModelSpec(method = "pls", tuneLength = 20),
svmLinear = caretModelSpec(method = "svmLinear", tuneLength = 10),
svmRadial = caretModelSpec(method = "svmRadial", tuneLength = 10),
svmPoly = caretModelSpec(method = "svmPoly", tuneLength = 3),
rf = caretModelSpec(method = "rf", tuneLength = 10),
gbm = caretModelSpec(method = "gbm")
)
# Cross validation paramters
outcome <- "logMIC"
y_vector <- train_prep %>% as.data.frame() %>% .[,outcome]
set.seed(123)
fivecv_5_multi <- trainControl(method = "repeatedcv",
number = 5,
repeats = 5,
verboseIter = TRUE,
allowParallel = TRUE,
savePredictions = "final",
index =
createMultiFolds(y_vector, 5, 5))
# Final dataset
Train_fs_logMic <- train_prep %>% select(logMIC,
fs_ga$optVariables) %>% as.data.frame()
# Regression logMIC
models_logMIC <- caretList(logMIC~., data = Train_fs_logMic,
trControl = fivecv_5_multi,
tuneList = models,
continue_on_fail = TRUE)
save(models_logMIC, file = "models_logMIC.rda")
View(models)
View(metric_logMIC)
View(metric_logMIC)
#_-------------------------------------------
#METRICAS
get_metric <- function(result_models, train_fs, outcome){
models_sel <- result_models %>% names()
tr_metric <- result_models %>%
.[models_sel] %>%
map(predict, train_fs) %>%
map(postResample, train_fs[,outcome]) %>%
bind_rows(.id = "model") %>%
mutate(set = "Train")
ts_metric <- result_models %>%
.[models_sel] %>%
map(predict, test_prep) %>%
map(postResample, test_prep %>% pull(outcome)) %>%
bind_rows(.id = "model") %>%
mutate(set = "Test")
if(outcome == "logMIC") {
cv_metric <- result_models %>%
.[models_sel] %>%
map(pluck, "resample") %>%
map(summarise, RMSE = mean(RMSE),
Rsquared = mean(Rsquared), MAE = mean(MAE)) %>%
bind_rows(., .id = "model") %>% mutate(set = "cv")
}
if(outcome != "logMIC") {
cv_metric <- result_models %>%
.[models_sel] %>%
map(pluck, "resample") %>%
map(summarise, Accuracy = mean(Accuracy),
Kappa = mean(Kappa)) %>%
bind_rows(., .id = "model") %>% mutate(set = "cv")
}
metric_models <- rbind(tr_metric, cv_metric, ts_metric) %>%   arrange(model)
}
metric_logMIC <- get_metric(models_logMIC, Train_fs_logMic, "logMIC")
xlsx::write.xlsx(metric_logMIC,file='metricslogMIC.xlsx')
View(metric_logMIC)
View(models_logMIC)
View(models_logMIC)
View(models)
View(models)
View(metric_logMIC)
View(metric_logMIC)
train_prep <- juice(rec_train)
test_prep <- bake(rec_train, new_data = test_input)
t0 = now()
# Filtro inicio
input_selected <- input %>%
rename(logMIC = "Mesure_(log)") %>%
rename(hoopwoods_1_mean = "hopp-woods_1_mean") %>%
filter(Cuantification_Type == "MIC" &
Target_Type =="Bacteria Gram Negative" &
Unity == "µg/ml"  &
is.na(Notes))
# Delete NA values in logMIC and filter Unity
input_naomit <- input_selected %>%
mutate(logMIC = as.numeric(logMIC)) %>%
drop_na(logMIC)
# Eliminar duplicados
input_naomit_out_dup <- input_naomit %>%
distinct(Sequences,.keep_all = TRUE)
ggpubr::gghistogram(input_naomit_out_dup$logMIC)
# Remove outlier in general
input_naomit_out_dup <-  input_naomit_out_dup %>%
rstatix::identify_outliers(logMIC) %>%
anti_join(input_naomit_out_dup,.)
#print(table(input$Genero))
###############
set.seed(321)
index <- createDataPartition(input_naomit_out_dup$logMIC,
p = .8, list = FALSE)
train_input <- input_naomit_out_dup[ index,]
test_input  <- input_naomit_out_dup[-index,]
# Check distributions
train_input %>% mutate(set = "Train") %>%
rbind(test_input %>% mutate(set = "Test")) %>%
ggplot(aes(logMIC, color = set)) +
geom_density()
# Seleccionar variables de informacion
train_info <- train_input %>%
select(Data_ID:References)
test_info <- test_input %>%
select(Data_ID:References)
# Seleccionar variable respuesta y descriptores
train_set <- train_input %>%
select(logMIC, Y:KGA)
test_set <- test_input %>%
select(logMIC, Y:KGA)
#PREPROCESAMIENTO
rec_train <- recipe(logMIC ~ . , data = train_set) %>%
step_nzv(all_predictors()) %>%
step_corr(all_numeric_predictors(), threshold = 0.85) %>%
#step_normalize(all_numeric_predictors()) %>%
step_scale(all_predictors()) %>%
prep()
train_prep <- juice(rec_train)
test_prep <- bake(rec_train, new_data = test_input)
train_prep <- juice(rec_train)
test_prep <- bake(rec_train, new_data = test_input)
setwd("C:/Users/eliez/OneDrive/Tesis y titulacion/Antimicrobial_Peptides_QSAR_Prediction_Project/Models/Regresion PeptidesVsGramN")
train_prep <- juice(rec_train)
test_prep <- bake(rec_train, new_data = test_input)
